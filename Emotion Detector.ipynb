{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"text_emotion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment       author  \\\n",
       "0  1956967341       empty   xoshayzers   \n",
       "1  1956967666     sadness    wannamama   \n",
       "2  1956967696     sadness    coolfunky   \n",
       "3  1956967789  enthusiasm  czareaquino   \n",
       "4  1956968416     neutral    xkilljoyx   \n",
       "\n",
       "                                             content  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                Funeral ceremony...gloomy friday...  \n",
       "3               wants to hang out with friends SOON!  \n",
       "4  @dannycastillo We want to trade with someone w...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('author',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1956968477</td>\n",
       "      <td>worry</td>\n",
       "      <td>Re-pinging @ghostridah14: why didn't you go to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1956968487</td>\n",
       "      <td>sadness</td>\n",
       "      <td>I should be sleep, but im not! thinking about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1956968636</td>\n",
       "      <td>worry</td>\n",
       "      <td>Hmmm. http://www.djhero.com/ is down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1956969035</td>\n",
       "      <td>sadness</td>\n",
       "      <td>@charviray Charlene my love. I miss you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1956969172</td>\n",
       "      <td>sadness</td>\n",
       "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment                                            content\n",
       "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
       "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
       "4  1956968416     neutral  @dannycastillo We want to trade with someone w...\n",
       "5  1956968477       worry  Re-pinging @ghostridah14: why didn't you go to...\n",
       "6  1956968487     sadness  I should be sleep, but im not! thinking about ...\n",
       "7  1956968636       worry               Hmmm. http://www.djhero.com/ is down\n",
       "8  1956969035     sadness            @charviray Charlene my love. I miss you\n",
       "9  1956969172     sadness         @kelcouch I'm sorry  at least it's Friday?"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['empty', 'sadness', 'enthusiasm', 'neutral', 'worry', 'surprise',\n",
       "       'love', 'fun', 'hate', 'happiness', 'boredom', 'relief', 'anger'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1956968477</td>\n",
       "      <td>worry</td>\n",
       "      <td>Re-pinging @ghostridah14: why didn't you go to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1956968487</td>\n",
       "      <td>sadness</td>\n",
       "      <td>I should be sleep, but im not! thinking about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1956968636</td>\n",
       "      <td>worry</td>\n",
       "      <td>Hmmm. http://www.djhero.com/ is down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1956969035</td>\n",
       "      <td>sadness</td>\n",
       "      <td>@charviray Charlene my love. I miss you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1956969172</td>\n",
       "      <td>sadness</td>\n",
       "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment                                            content\n",
       "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
       "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
       "4  1956968416     neutral  @dannycastillo We want to trade with someone w...\n",
       "5  1956968477       worry  Re-pinging @ghostridah14: why didn't you go to...\n",
       "6  1956968487     sadness  I should be sleep, but im not! thinking about ...\n",
       "7  1956968636       worry               Hmmm. http://www.djhero.com/ is down\n",
       "8  1956969035     sadness            @charviray Charlene my love. I miss you\n",
       "9  1956969172     sadness         @kelcouch I'm sorry  at least it's Friday?"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content'] = data['content'].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content'] = data['content'].str.replace('[^\\w\\s]',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>tiffanylue i know i was listenin to bad habit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>layin n bed with a headache ughhhh   waitin on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>funeral ceremony   gloomy friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>dannycastillo we want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment                                            content\n",
       "0  1956967341       empty   tiffanylue i know i was listenin to bad habit...\n",
       "1  1956967666     sadness  layin n bed with a headache ughhhh   waitin on...\n",
       "2  1956967696     sadness                funeral ceremony   gloomy friday   \n",
       "3  1956967789  enthusiasm               wants to hang out with friends soon \n",
       "4  1956968416     neutral   dannycastillo we want to trade with someone w..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "data['content'] = data['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "l = WordNetLemmatizer()\n",
    "data['content'] = data['content'].apply(lambda x: \" \".join([l.lemmatize(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    tiffanylue know listenin bad habit earlier sta...\n",
       "1              layin n bed headache ughhhh waitin call\n",
       "2                       funeral ceremony gloomy friday\n",
       "3                                want hang friend soon\n",
       "4    dannycastillo want trade someone houston ticke...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['content'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def de_repeat(text):\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return pattern.sub(r\"\\1\\1\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content'] = data['content'].apply(lambda x: \" \".join(de_repeat(x) for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = pd.Series(' '.join(data['content']).split()).value_counts()[-10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = list(freq.index)\n",
    "data['content'] = data['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(data.sentiment.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chaitu\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['anger',\n",
       " 'boredom',\n",
       " 'empty',\n",
       " 'enthusiasm',\n",
       " 'fun',\n",
       " 'happiness',\n",
       " 'hate',\n",
       " 'love',\n",
       " 'neutral',\n",
       " 'relief',\n",
       " 'sadness',\n",
       " 'surprise',\n",
       " 'worry']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(lbl_enc.inverse_transform([0,1,2,3,4,5,6,7,8,9,10,11,12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data.content.values,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(min_df=5,ngram_range=(1,5)).fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '05',\n",
       " '06',\n",
       " '08',\n",
       " '09',\n",
       " '10',\n",
       " '10 30',\n",
       " '10 day',\n",
       " '10 min',\n",
       " '10 minute',\n",
       " '10 year',\n",
       " '100',\n",
       " '100th',\n",
       " '10am',\n",
       " '10pm',\n",
       " '10th',\n",
       " '11',\n",
       " '11 11',\n",
       " '12',\n",
       " '12 hour',\n",
       " '12th',\n",
       " '13',\n",
       " '14',\n",
       " '14 hour',\n",
       " '140',\n",
       " '140 character',\n",
       " '15',\n",
       " '15 min',\n",
       " '15 minute',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '18th',\n",
       " '19',\n",
       " '1am',\n",
       " '1st',\n",
       " '1st time',\n",
       " '20',\n",
       " '200',\n",
       " '2008',\n",
       " '2009',\n",
       " '2010',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '24 hour',\n",
       " '24 hr',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '2am',\n",
       " '2b',\n",
       " '2day',\n",
       " '2moro',\n",
       " '2morrow',\n",
       " '2nd',\n",
       " '2night',\n",
       " '2nite',\n",
       " '2pm',\n",
       " '2uhs',\n",
       " '30',\n",
       " '30 min',\n",
       " '30 minute',\n",
       " '300',\n",
       " '30am',\n",
       " '30pm',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '35',\n",
       " '360',\n",
       " '38',\n",
       " '3am',\n",
       " '3d',\n",
       " '3d movie',\n",
       " '3rd',\n",
       " '40',\n",
       " '400',\n",
       " '45',\n",
       " '45am',\n",
       " '48',\n",
       " '4am',\n",
       " '4pm',\n",
       " '4th',\n",
       " '4th happy',\n",
       " '4th happy star',\n",
       " '4th happy star war',\n",
       " '4th happy star war day',\n",
       " '4th quot',\n",
       " '50',\n",
       " '500',\n",
       " '5am',\n",
       " '5k',\n",
       " '5pm',\n",
       " '5th',\n",
       " '60',\n",
       " '6am',\n",
       " '6pm',\n",
       " '6th',\n",
       " '70',\n",
       " '75',\n",
       " '7am',\n",
       " '7pm',\n",
       " '7th',\n",
       " '80',\n",
       " '8am',\n",
       " '8th',\n",
       " '90',\n",
       " '900',\n",
       " '95',\n",
       " '99',\n",
       " '9am',\n",
       " '9th',\n",
       " '__',\n",
       " '_supernatural_',\n",
       " 'aa',\n",
       " 'aah',\n",
       " 'aahh',\n",
       " 'aaron',\n",
       " 'aaww',\n",
       " 'ab',\n",
       " 'abandoned',\n",
       " 'abby',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'able get',\n",
       " 'able go',\n",
       " 'able make',\n",
       " 'absolutely',\n",
       " 'abt',\n",
       " 'ac',\n",
       " 'academy',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'access',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'accomplished',\n",
       " 'according',\n",
       " 'account',\n",
       " 'ace',\n",
       " 'ace cake',\n",
       " 'ache',\n",
       " 'aching',\n",
       " 'ack',\n",
       " 'aclockworktoad',\n",
       " 'across',\n",
       " 'act',\n",
       " 'act like',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'active',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actress',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'actually really',\n",
       " 'ad',\n",
       " 'ada',\n",
       " 'adam',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addicted',\n",
       " 'addiction',\n",
       " 'adding',\n",
       " 'address',\n",
       " 'admin',\n",
       " 'admit',\n",
       " 'adorable',\n",
       " 'adore',\n",
       " 'adult',\n",
       " 'advance',\n",
       " 'advantage',\n",
       " 'adventure',\n",
       " 'advert',\n",
       " 'advice',\n",
       " 'afford',\n",
       " 'afraid',\n",
       " 'afternoon',\n",
       " 'afterwards',\n",
       " 'age',\n",
       " 'agency',\n",
       " 'agent',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'ah',\n",
       " 'ah well',\n",
       " 'aha',\n",
       " 'ahah',\n",
       " 'ahaha',\n",
       " 'ahahaha',\n",
       " 'ahead',\n",
       " 'ahh',\n",
       " 'ahh im',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aim',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'airline',\n",
       " 'airport',\n",
       " 'aka',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alarm',\n",
       " 'album',\n",
       " 'alcohol',\n",
       " 'alex',\n",
       " 'algebra',\n",
       " 'ali',\n",
       " 'alice',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'allah',\n",
       " 'allen',\n",
       " 'allergic',\n",
       " 'allergy',\n",
       " 'allowed',\n",
       " 'almond',\n",
       " 'almost',\n",
       " 'almost done',\n",
       " 'almost got',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alot',\n",
       " 'alpha',\n",
       " 'already',\n",
       " 'already done',\n",
       " 'already got',\n",
       " 'already miss',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'also want',\n",
       " 'although',\n",
       " 'always',\n",
       " 'always feel',\n",
       " 'always forget',\n",
       " 'always get',\n",
       " 'always good',\n",
       " 'always love',\n",
       " 'always make',\n",
       " 'always seem',\n",
       " 'amazing',\n",
       " 'amazing day',\n",
       " 'amazing lt',\n",
       " 'amazing night',\n",
       " 'amazingly',\n",
       " 'amazon',\n",
       " 'amazon gift',\n",
       " 'amazon gift card',\n",
       " 'amber',\n",
       " 'amber_benson',\n",
       " 'amen',\n",
       " 'america',\n",
       " 'american',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'amp amp',\n",
       " 'amp family',\n",
       " 'amp go',\n",
       " 'amp got',\n",
       " 'amp happy',\n",
       " 'amp im',\n",
       " 'amp love',\n",
       " 'amp make',\n",
       " 'amp never',\n",
       " 'amp quot',\n",
       " 'amp still',\n",
       " 'amusing',\n",
       " 'amy',\n",
       " 'anatomy',\n",
       " 'andrew',\n",
       " 'android',\n",
       " 'andy',\n",
       " 'andyclemmensen',\n",
       " 'ang',\n",
       " 'angel',\n",
       " 'angry',\n",
       " 'animal',\n",
       " 'animation',\n",
       " 'anime',\n",
       " 'ankle',\n",
       " 'anna',\n",
       " 'anne',\n",
       " 'anniversary',\n",
       " 'announced',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annual',\n",
       " 'another',\n",
       " 'another day',\n",
       " 'another friday',\n",
       " 'another friday night',\n",
       " 'another good',\n",
       " 'another hour',\n",
       " 'another long',\n",
       " 'another note',\n",
       " 'another one',\n",
       " 'another two',\n",
       " 'another week',\n",
       " 'answer',\n",
       " 'answer question',\n",
       " 'answered',\n",
       " 'ant',\n",
       " 'anthony',\n",
       " 'anti',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'any1',\n",
       " 'anybody',\n",
       " 'anyhoo',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anyone else',\n",
       " 'anyone got',\n",
       " 'anyone know',\n",
       " 'anyone want',\n",
       " 'anything',\n",
       " 'anything else',\n",
       " 'anytime',\n",
       " 'anytime soon',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'ap',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'aplusk',\n",
       " 'apology',\n",
       " 'app',\n",
       " 'apparently',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'apple',\n",
       " 'apple store',\n",
       " 'application',\n",
       " 'applied',\n",
       " 'appointment',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciation',\n",
       " 'approaching',\n",
       " 'apps',\n",
       " 'apps facebook',\n",
       " 'apps facebook com',\n",
       " 'apps facebook com dogbook',\n",
       " 'apps facebook com dogbook profile',\n",
       " 'appt',\n",
       " 'apt',\n",
       " 'archuleta',\n",
       " 'area',\n",
       " 'arent',\n",
       " 'argh',\n",
       " 'arghh',\n",
       " 'argument',\n",
       " 'arm',\n",
       " 'army',\n",
       " 'around',\n",
       " 'around house',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arriving',\n",
       " 'art',\n",
       " 'article',\n",
       " 'artist',\n",
       " 'as',\n",
       " 'asap',\n",
       " 'ashamed',\n",
       " 'ashley',\n",
       " 'ashley tisdale',\n",
       " 'ashleytisdale',\n",
       " 'asian',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asks',\n",
       " 'asleep',\n",
       " 'asshole',\n",
       " 'assignment',\n",
       " 'assistant',\n",
       " 'assume',\n",
       " 'aswell',\n",
       " 'asylum',\n",
       " 'ate',\n",
       " 'atl',\n",
       " 'atleast',\n",
       " 'atm',\n",
       " 'attack',\n",
       " 'attacked',\n",
       " 'attacking',\n",
       " 'attempt',\n",
       " 'attempting',\n",
       " 'attend',\n",
       " 'attending',\n",
       " 'attention',\n",
       " 'attic',\n",
       " 'attitude',\n",
       " 'au',\n",
       " 'audience',\n",
       " 'audio',\n",
       " 'audition',\n",
       " 'august',\n",
       " 'aunt',\n",
       " 'auntie',\n",
       " 'aussie',\n",
       " 'aussiecynic',\n",
       " 'austin',\n",
       " 'australia',\n",
       " 'author',\n",
       " 'auto',\n",
       " 'automatically',\n",
       " 'available',\n",
       " 'avatar',\n",
       " 'avenue',\n",
       " 'avoid',\n",
       " 'aw',\n",
       " 'awake',\n",
       " 'award',\n",
       " 'away',\n",
       " 'awe',\n",
       " 'awesome',\n",
       " 'awesome day',\n",
       " 'awesome love',\n",
       " 'awesome time',\n",
       " 'awesomeness',\n",
       " 'awesomness',\n",
       " 'awful',\n",
       " 'awh',\n",
       " 'awhile',\n",
       " 'awkward',\n",
       " 'awsome',\n",
       " 'aww',\n",
       " 'aww cute',\n",
       " 'aww hope',\n",
       " 'aww love',\n",
       " 'aww man',\n",
       " 'aww miss',\n",
       " 'aww poor',\n",
       " 'aww sad',\n",
       " 'aww sorry',\n",
       " 'aww suck',\n",
       " 'aww sweet',\n",
       " 'aww thank',\n",
       " 'aww thanks',\n",
       " 'aww thats',\n",
       " 'aww well',\n",
       " 'aww wish',\n",
       " 'awwh',\n",
       " 'ay',\n",
       " 'aye',\n",
       " 'az',\n",
       " 'b4',\n",
       " 'ba',\n",
       " 'babe',\n",
       " 'baby',\n",
       " 'baby girl',\n",
       " 'babygirlparis',\n",
       " 'babysitting',\n",
       " 'babyy',\n",
       " 'back',\n",
       " 'back bed',\n",
       " 'back garden',\n",
       " 'back good',\n",
       " 'back great',\n",
       " 'back gym',\n",
       " 'back home',\n",
       " 'back hurt',\n",
       " 'back later',\n",
       " 'back leg',\n",
       " 'back long',\n",
       " 'back office',\n",
       " 'back online',\n",
       " 'back school',\n",
       " 'back sleep',\n",
       " 'back soon',\n",
       " 'back today',\n",
       " 'back tomorrow',\n",
       " 'back work',\n",
       " 'back work today',\n",
       " 'back work tomorrow',\n",
       " 'background',\n",
       " 'backstreetboys',\n",
       " 'backup',\n",
       " 'backyard',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'bad day',\n",
       " 'bad get',\n",
       " 'bad headache',\n",
       " 'bad idea',\n",
       " 'bad mood',\n",
       " 'bad news',\n",
       " 'bad thing',\n",
       " 'bad time',\n",
       " 'badge',\n",
       " 'badly',\n",
       " 'bag',\n",
       " 'bah',\n",
       " 'bahaha',\n",
       " 'bak',\n",
       " 'bake',\n",
       " 'baked',\n",
       " 'baking',\n",
       " 'ball',\n",
       " 'banana',\n",
       " 'band',\n",
       " 'bang',\n",
       " 'banging',\n",
       " 'bank',\n",
       " 'bank holiday',\n",
       " 'bank holiday monday',\n",
       " 'banquet',\n",
       " 'bar',\n",
       " 'barely',\n",
       " 'base',\n",
       " 'baseball',\n",
       " 'baseball game',\n",
       " 'based',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basketball',\n",
       " 'bass',\n",
       " 'bastard',\n",
       " 'bath',\n",
       " 'bathroom',\n",
       " 'batman',\n",
       " 'battery',\n",
       " 'battle',\n",
       " 'bay',\n",
       " 'bb',\n",
       " 'bb517',\n",
       " 'bbl',\n",
       " 'bbq',\n",
       " 'bbq today',\n",
       " 'bby',\n",
       " 'bc',\n",
       " 'bday',\n",
       " 'bday party',\n",
       " 'bea',\n",
       " 'bea09',\n",
       " 'beach',\n",
       " 'bean',\n",
       " 'bear',\n",
       " 'beard',\n",
       " 'beast',\n",
       " 'beat',\n",
       " 'beautiful',\n",
       " 'beautiful day',\n",
       " 'beautiful morning',\n",
       " 'beautiful sunny',\n",
       " 'beauty',\n",
       " 'became',\n",
       " 'become',\n",
       " 'becoming',\n",
       " 'becuz',\n",
       " 'bed',\n",
       " 'bed early',\n",
       " 'bed good',\n",
       " 'bed good night',\n",
       " 'bed goodnight',\n",
       " 'bed happy',\n",
       " 'bed happy mother',\n",
       " 'bed happy mother day',\n",
       " 'bed night',\n",
       " 'bed soon',\n",
       " 'bed time',\n",
       " 'bedroom',\n",
       " 'bedtime',\n",
       " 'bee',\n",
       " 'beer',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'behind',\n",
       " 'bein',\n",
       " 'believe',\n",
       " 'belive',\n",
       " 'bell',\n",
       " 'bella',\n",
       " 'belly',\n",
       " 'beloved',\n",
       " 'ben',\n",
       " 'benefit',\n",
       " 'berry',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'best day',\n",
       " 'best friend',\n",
       " 'best movie',\n",
       " 'best part',\n",
       " 'best show',\n",
       " 'best thing',\n",
       " 'best wish',\n",
       " 'bestie',\n",
       " 'besties',\n",
       " 'besties ddlovato',\n",
       " 'bet',\n",
       " 'beta',\n",
       " 'better',\n",
       " 'better better',\n",
       " 'better day',\n",
       " 'better get',\n",
       " 'better good',\n",
       " 'better one',\n",
       " 'better soon',\n",
       " 'better today',\n",
       " 'betty',\n",
       " 'beyonce',\n",
       " 'beyond',\n",
       " 'bf',\n",
       " 'bff',\n",
       " 'bgt',\n",
       " 'bible',\n",
       " 'bicycle',\n",
       " 'big',\n",
       " 'big fan',\n",
       " 'big time',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'bike ride',\n",
       " 'bill',\n",
       " 'billy',\n",
       " 'bin',\n",
       " 'bing',\n",
       " 'bio',\n",
       " 'biology',\n",
       " 'bird',\n",
       " 'birthday',\n",
       " 'birthday day',\n",
       " 'birthday party',\n",
       " 'bit',\n",
       " 'bit ly',\n",
       " 'bitch',\n",
       " 'bite',\n",
       " 'bitter',\n",
       " 'biz',\n",
       " 'bk',\n",
       " 'bkite',\n",
       " 'bkite com',\n",
       " 'black',\n",
       " 'blackberry',\n",
       " 'blah',\n",
       " 'blahh',\n",
       " 'blame',\n",
       " 'blank',\n",
       " 'blanket',\n",
       " 'blast',\n",
       " 'bleh',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blessed day',\n",
       " 'blessing',\n",
       " 'blew',\n",
       " 'blind',\n",
       " 'blink',\n",
       " 'blip',\n",
       " 'blip fm',\n",
       " 'bliss',\n",
       " 'blister',\n",
       " 'block',\n",
       " 'block party',\n",
       " 'blocked',\n",
       " 'blog',\n",
       " 'blog http',\n",
       " 'blog post',\n",
       " 'blogger',\n",
       " 'blogging',\n",
       " 'blogspot',\n",
       " 'blogspot com',\n",
       " 'blogtv',\n",
       " 'blonde',\n",
       " 'blood',\n",
       " 'bloody',\n",
       " 'blow',\n",
       " 'blowing',\n",
       " 'blown',\n",
       " 'blue',\n",
       " 'board',\n",
       " 'boat',\n",
       " 'bob',\n",
       " 'body',\n",
       " 'bom',\n",
       " 'bomb',\n",
       " 'bone',\n",
       " 'bonus',\n",
       " 'boo',\n",
       " 'boo hoo',\n",
       " 'boob',\n",
       " 'boohoo',\n",
       " 'book',\n",
       " 'booked',\n",
       " 'booking',\n",
       " 'boom',\n",
       " 'boot',\n",
       " 'booze',\n",
       " 'border',\n",
       " 'bored',\n",
       " 'bored nothing',\n",
       " 'bored work',\n",
       " 'boredd',\n",
       " 'boredom',\n",
       " 'boring',\n",
       " 'born',\n",
       " 'borrow',\n",
       " 'bos',\n",
       " 'boston',\n",
       " 'bot',\n",
       " 'bother',\n",
       " 'bothered',\n",
       " 'bottle',\n",
       " 'bottom',\n",
       " 'bought',\n",
       " 'bound',\n",
       " 'bout',\n",
       " 'bout go',\n",
       " 'bowl',\n",
       " 'bowling',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boy tell',\n",
       " 'boy tell em',\n",
       " 'boy tell em live',\n",
       " 'boy tell em live live',\n",
       " 'boyfriend',\n",
       " 'brace',\n",
       " 'brad',\n",
       " 'bradie',\n",
       " 'bradiewebbstack',\n",
       " 'brain',\n",
       " 'brand',\n",
       " 'brand new',\n",
       " 'brandon',\n",
       " 'brave',\n",
       " 'brazil',\n",
       " 'brb',\n",
       " 'bread',\n",
       " 'break',\n",
       " 'break heart',\n",
       " 'breakfast',\n",
       " 'breaking',\n",
       " 'breast',\n",
       " 'breath',\n",
       " 'breathe',\n",
       " 'brian',\n",
       " 'brianmcnugget',\n",
       " 'brick',\n",
       " 'bride',\n",
       " 'bridge',\n",
       " 'bright',\n",
       " 'bright side',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'bring back',\n",
       " 'bringing',\n",
       " 'brings',\n",
       " 'brings back',\n",
       " 'brit',\n",
       " 'britain',\n",
       " 'britain got',\n",
       " 'britain got talent',\n",
       " 'british',\n",
       " 'britney',\n",
       " 'bro',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brooklyn',\n",
       " 'bros',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brownie',\n",
       " 'browser',\n",
       " 'browsing',\n",
       " 'bruce',\n",
       " 'bruised',\n",
       " 'brunch',\n",
       " 'bt',\n",
       " 'btw',\n",
       " 'btw happy',\n",
       " 'btw happy mother',\n",
       " 'btw happy mother day',\n",
       " 'btw still',\n",
       " 'bubble',\n",
       " 'buck',\n",
       " 'bud',\n",
       " 'buddy',\n",
       " 'buffalo',\n",
       " 'bug',\n",
       " 'bugger',\n",
       " 'build',\n",
       " 'building',\n",
       " 'built',\n",
       " 'bull',\n",
       " 'bullshit',\n",
       " 'bum',\n",
       " 'bummed',\n",
       " 'bummer',\n",
       " 'bump',\n",
       " 'bunch',\n",
       " 'bunny',\n",
       " 'burbank',\n",
       " 'burger',\n",
       " 'burn',\n",
       " 'burned',\n",
       " 'burning',\n",
       " 'burnt',\n",
       " 'burrito',\n",
       " 'bus',\n",
       " 'bush',\n",
       " 'business',\n",
       " 'bust',\n",
       " 'busy',\n",
       " 'busy busy',\n",
       " 'busy day',\n",
       " 'busy work',\n",
       " 'butt',\n",
       " 'butter',\n",
       " 'butterfly',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buy new',\n",
       " 'buy one',\n",
       " 'buying',\n",
       " 'buzz',\n",
       " 'bye',\n",
       " 'bye bye',\n",
       " 'byee',\n",
       " 'ca',\n",
       " 'cab',\n",
       " 'cable',\n",
       " 'cafe',\n",
       " 'cage',\n",
       " 'cake',\n",
       " 'calendar',\n",
       " 'cali',\n",
       " 'california',\n",
       " 'call',\n",
       " 'call back',\n",
       " 'called',\n",
       " 'called quot',\n",
       " 'callin',\n",
       " 'calling',\n",
       " 'calling name',\n",
       " 'calm',\n",
       " 'calvinharris',\n",
       " 'cam',\n",
       " 'came',\n",
       " 'came back',\n",
       " 'came home',\n",
       " 'camera',\n",
       " 'camp',\n",
       " 'camping',\n",
       " 'canada',\n",
       " 'cancel',\n",
       " 'canceled',\n",
       " 'cancelled',\n",
       " 'cancer',\n",
       " 'candy',\n",
       " 'cannot',\n",
       " 'cannot wait',\n",
       " 'cant',\n",
       " 'cant believe',\n",
       " 'cant belive',\n",
       " 'cant even',\n",
       " 'cant find',\n",
       " 'cant get',\n",
       " 'cant go',\n",
       " 'cant sleep',\n",
       " 'cant wait',\n",
       " 'cant wait see',\n",
       " 'cant wait till',\n",
       " 'canuck',\n",
       " 'canï',\n",
       " 'canï ½t',\n",
       " 'cap',\n",
       " 'cape',\n",
       " 'capital',\n",
       " 'captain',\n",
       " 'car',\n",
       " 'car accident',\n",
       " 'car back',\n",
       " 'card',\n",
       " 'card happy',\n",
       " 'card happy mother',\n",
       " 'card happy mother day',\n",
       " 'card lovely',\n",
       " 'card lovely daughter',\n",
       " 'card lovely daughter wishing',\n",
       " 'card lovely daughter wishing happy',\n",
       " 'care',\n",
       " 'career',\n",
       " 'careful',\n",
       " 'carnival',\n",
       " 'carolina',\n",
       " 'carrie',\n",
       " 'carry',\n",
       " 'cartoon',\n",
       " 'casa',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'cast',\n",
       " 'castle',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'catching',\n",
       " 'category',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'cause dont',\n",
       " 'cause im',\n",
       " 'cavs',\n",
       " 'cba',\n",
       " 'cc',\n",
       " 'cd',\n",
       " 'celebrate',\n",
       " 'celebrated',\n",
       " 'celebrating',\n",
       " 'celebrating mother',\n",
       " 'celebrating mother day',\n",
       " 'celebration',\n",
       " 'celebrity',\n",
       " 'cell',\n",
       " 'cell phone',\n",
       " 'cellphone',\n",
       " 'cent',\n",
       " 'center',\n",
       " 'central',\n",
       " 'centre',\n",
       " 'cereal',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'ch',\n",
       " 'cha',\n",
       " 'chai',\n",
       " 'chain',\n",
       " 'chair',\n",
       " 'challenge',\n",
       " 'champ',\n",
       " 'champion',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'change pic',\n",
       " 'changed',\n",
       " 'changing',\n",
       " 'channel',\n",
       " 'chap',\n",
       " 'chapter',\n",
       " 'char',\n",
       " 'character',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'charger',\n",
       " 'charity',\n",
       " 'charlie',\n",
       " 'charm',\n",
       " 'chase',\n",
       " 'chat',\n",
       " 'chatting',\n",
       " 'cheap',\n",
       " 'cheating',\n",
       " 'check',\n",
       " 'check http',\n",
       " 'check new',\n",
       " 'checked',\n",
       " 'checkin',\n",
       " 'checking',\n",
       " 'cheek',\n",
       " 'cheer',\n",
       " 'cheese',\n",
       " 'cheesecake',\n",
       " 'cheesy',\n",
       " 'chef',\n",
       " 'chelsea',\n",
       " 'chem',\n",
       " 'chemistry',\n",
       " 'cherry',\n",
       " 'chest',\n",
       " 'chi',\n",
       " 'chicago',\n",
       " 'chick',\n",
       " 'chicken',\n",
       " 'chicken soup',\n",
       " 'child',\n",
       " 'chili',\n",
       " 'chill',\n",
       " 'chilled',\n",
       " 'chillin',\n",
       " 'chilling',\n",
       " 'chilly',\n",
       " 'chin',\n",
       " 'china',\n",
       " 'chinese',\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecv = vec.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(vecv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames  = np.array(vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = model.coef_[0].argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['see', 'still', 'miss', 'thanks', 'oh', 'night', 'today',\n",
       "       'twitter', 'morning', 'happy'], dtype='<U43')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames[mc[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bout', 'hard', 'link', 'left', 'seriously', 'mummy', 'sister',\n",
       "       'fucking', 'gah', 'taste'], dtype='<U43')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames[mc[-11:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(vec.transform([\"He is good\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = vec.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3362"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chaitu\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc.fit(vecv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre  = rc.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2854"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pre,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb.fit(vecv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "p =  mb.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3266"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(p,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "zc = mb.coef_[0].argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb.predict(vec.transform([\"Uska is a good girl\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    1,    3,    0,    0,    9,    2,    4,\n",
       "           1,   10],\n",
       "       [   0,    0,    1,    0,    1,    4,    3,    2,   12,    1,    5,\n",
       "           1,   20],\n",
       "       [   0,    1,    0,    1,    0,    9,    3,    6,  121,    0,   15,\n",
       "           0,   46],\n",
       "       [   0,    0,    1,    0,    3,   28,    2,   12,   80,    4,   13,\n",
       "           2,   60],\n",
       "       [   0,    0,    0,    1,   17,  113,    2,   33,  162,    6,   30,\n",
       "           8,   82],\n",
       "       [   0,    0,    0,    3,   33,  415,    5,  161,  404,   24,   49,\n",
       "          39,  158],\n",
       "       [   0,    1,    1,    0,    5,   11,   59,    8,   85,    3,   57,\n",
       "           9,   79],\n",
       "       [   0,    0,    0,    0,   15,  174,    5,  388,  170,    5,   44,\n",
       "          11,   81],\n",
       "       [   0,    1,    1,    1,   25,  199,   13,   78, 1226,   21,  119,\n",
       "          30,  433],\n",
       "       [   0,    0,    0,    1,    5,   63,    4,   28,  144,   13,   22,\n",
       "           4,   63],\n",
       "       [   0,    0,    5,    0,   14,   66,   40,   43,  335,   10,  364,\n",
       "          19,  413],\n",
       "       [   0,    0,    0,    0,    9,   77,    4,   34,  194,    6,   48,\n",
       "          29,  115],\n",
       "       [   0,    0,    2,    1,   20,  156,   28,   80,  704,   20,  322,\n",
       "          54,  851]], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
